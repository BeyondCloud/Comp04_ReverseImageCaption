{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import model\n",
    "import pickle\n",
    "from os.path import join\n",
    "import h5py\n",
    "from Utils import image_processing\n",
    "import scipy.misc\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "resume_model = './Data/Models/ep_10_nice1152.ckpt'\n",
    "# resume_model = './Data/Models/temp.ckpt'\n",
    "\n",
    "def initialize_uninitialized_vars(sess):\n",
    "    from itertools import compress\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([~(tf.is_variable_initialized(var)) \\\n",
    "                                   for var in global_vars])\n",
    "    not_initialized_vars = list(compress(global_vars, is_not_initialized))\n",
    "\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "def load_training_data(data_dir):\n",
    "\n",
    "    h = h5py.File(join(data_dir, 'flower_train.h5'))\n",
    "    flower_captions = {}\n",
    "    for ds in h.items():\n",
    "        flower_captions[ds[0]] = np.array(ds[1])\n",
    "    image_list = [key for key in flower_captions]\n",
    "    image_list.sort()\n",
    "\n",
    "    # img_75 = int(len(image_list))\n",
    "    # training_image_list = image_list[0:img_75]\n",
    "\n",
    "    random.shuffle(image_list)\n",
    "    total_img_cnt = len(image_list)\n",
    "    print(total_img_cnt)\n",
    "    return {\n",
    "        'image_list' : image_list, # image name\n",
    "        'captions' : flower_captions, #flower_captions['image_00001.jpg'].shape (5,4800) 5 captions 4800 value for each \n",
    "        'data_length' : total_img_cnt\n",
    "    }\n",
    "\n",
    "\n",
    "def visualize_G(data_dir, real_images, generated_images, image_files):\n",
    "    \n",
    "    batch_size = real_images.shape[0]\n",
    "\n",
    "    w = int(batch_size/8)\n",
    "    h = int(batch_size/w)\n",
    "    fake_all = np.zeros( (64*w,64*h,3), dtype=np.float32)   \n",
    "\n",
    "    real_all = np.zeros( (64*w,64*h,3), dtype=np.float32) \n",
    "\n",
    "\n",
    "    print('w,h',w,h)\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            fake_all[i*64:(i+1)*64,j*64:(j+1)*64,:] = (generated_images[i*h+j,:,:,:])\n",
    "\n",
    "    # scipy.misc.imsave(join(data_dir, 'samples/fake_all.jpg'),fake_all)\n",
    "\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            real_all[i*64:(i+1)*64,j*64:(j+1)*64,:] = (real_images[i*h+j,:,:,:])\n",
    "\n",
    "    # scipy.misc.imsave(join(data_dir, 'samples/real_all.jpg'),real_all)\n",
    "\n",
    "    both = np.zeros( (2*64*w,64*h,3), dtype=np.float32) \n",
    "    both[:64*w,:,:] = fake_all;\n",
    "    both[64*w:,:,:] = real_all;\n",
    "    # both = color.rgb2gray(both)\n",
    "    scipy.misc.imsave(join(data_dir, 'samples/both.jpg'),both)\n",
    "\n",
    "\n",
    "\n",
    "def batch_gen(batch_no, batch_size, image_size, z_dim, \n",
    "    caption_vector_length, split, data_dir, loaded_data = None):\n",
    "\n",
    "\n",
    "    real_images = np.zeros((batch_size, 64, 64, 3))\n",
    "    wrong_images = np.zeros((batch_size, 64, 64, 3))\n",
    "    captions = np.zeros((batch_size, caption_vector_length))\n",
    "\n",
    "    cnt = 0\n",
    "    image_files = []\n",
    "    for i in range(batch_no * batch_size, batch_no * batch_size + batch_size):\n",
    "        idx = i % len(loaded_data['image_list'])\n",
    "        image_file =  join(data_dir, 'flowers/jpg/'+loaded_data['image_list'][idx])\n",
    "        image_array = image_processing.load_image_array(image_file, image_size)\n",
    "        # image_array = image_array/255.0*2-1\n",
    "        real_images[cnt,:,:,:] = image_array\n",
    "\n",
    "        # Improve this selection of wrong image\n",
    "        wrong_image_id = random.randint(0,len(loaded_data['image_list'])-1)\n",
    "        wrong_image_file =  join(data_dir, 'flowers/jpg/'+loaded_data['image_list'][wrong_image_id])\n",
    "        wrong_image_array = image_processing.load_image_array(wrong_image_file, image_size)\n",
    "        # wrong_image_array = wrong_image_array/255.0*2-1\n",
    "        wrong_images[cnt, :,:,:] = wrong_image_array\n",
    "\n",
    "        random_caption = random.randint(0,4)\n",
    "        captions[cnt,:] = loaded_data['captions'][ loaded_data['image_list'][idx] ][ random_caption ][:caption_vector_length]\n",
    "        image_files.append( image_file )\n",
    "        cnt += 1\n",
    "\n",
    "    # z_noise = np.random.uniform(-1, 1, [batch_size, z_dim])\n",
    "    z_noise = np.random.normal(0, 0.1,  [batch_size, z_dim])\n",
    "    return real_images, wrong_images, captions, z_noise, image_files\n",
    "\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "data_dir = \"Data\"\n",
    "image_size = 64\n",
    "z_dim = 100\n",
    "caption_vector_length = 4800\n",
    "model_options = {\n",
    "    'z_dim' : z_dim,\n",
    "    't_dim' :256,\n",
    "    'batch_size' : batch_size,\n",
    "    'image_size' :64,\n",
    "    'gf_dim' : 64,\n",
    "    'df_dim' : 64,\n",
    "    'gfc_dim' :1024,\n",
    "    'caption_vector_length' : caption_vector_length\n",
    "}\n",
    "\n",
    "\n",
    "gan = model.GAN(model_options)\n",
    "\n",
    "input_tensors, variables, loss, outputs, checks,debug = gan.build_model()\n",
    "d_optim = tf.train.AdamOptimizer(0.000001, beta1 = 0.5).minimize(loss['d'], var_list=variables['d'])\n",
    "g_optim = tf.train.AdamOptimizer(0.000001, beta1 = 0.5).minimize(loss['g'], var_list=variables['g'])\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config = config)\n",
    "tf.global_variables_initializer().run()\n",
    "# initialize_uninitialized_vars(sess)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if resume_model:\n",
    "    saver.restore(sess, resume_model)\n",
    "    print('model restore:', resume_model)\n",
    "\n",
    "variables_names = [v.name for v in tf.trainable_variables()]\n",
    "values = sess.run(variables_names)\n",
    "# for k, v in zip(variables_names, values):\n",
    "#     print(\"Variable: \", k)\n",
    "#     print(\"Shape: \", v.shape)\n",
    "#     print(v)\n",
    "\n",
    "\n",
    "\n",
    "loaded_data = load_training_data(data_dir)\n",
    "batches_per_epoch =  int(loaded_data['data_length']/batch_size)\n",
    "print(loaded_data['data_length'])\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"ep\",i)\n",
    "    for batch_no in range(batches_per_epoch):\n",
    "        real_images, wrong_images, caption_vectors, z_noise, image_files = batch_gen(batch_no, batch_size,\n",
    "            image_size, z_dim, caption_vector_length, 'train', data_dir,  loaded_data)\n",
    "\n",
    "        # DISCR UPDATE\n",
    "        check_ts = [ checks['d_loss1'] , checks['d_loss2'], checks['d_loss3']]\n",
    "        \n",
    "        ##DON’t CHANGE FOR RANGE, KEEP IT 1!!!!\n",
    "        for _ in range(1):\n",
    "            _, d_loss, gen, d1, d2, d3 = sess.run([d_optim, loss['d'], outputs['generator']] + check_ts,\n",
    "                feed_dict = {\n",
    "                    input_tensors['t_real_image'] : real_images,\n",
    "                    input_tensors['t_wrong_image'] : wrong_images,\n",
    "                    input_tensors['t_real_caption'] : caption_vectors,\n",
    "                    input_tensors['t_z'] : z_noise,\n",
    "                })\n",
    "\n",
    "        print(\"real/wrong/fake/total loss:\",d1,d2,d3,d_loss)\n",
    "\n",
    "        # GEN UPDATE\n",
    "        ##DON’t CHANGE FOR RANGE, KEEP IT 1!!!!\n",
    "        for _ in range(1):\n",
    "            _, g_loss, gen,de = sess.run([g_optim, loss['g'], outputs['generator'],debug],\n",
    "                feed_dict = {\n",
    "                    input_tensors['t_real_image'] : real_images,\n",
    "                    input_tensors['t_wrong_image'] : wrong_images,\n",
    "                    input_tensors['t_real_caption'] : caption_vectors,\n",
    "                    input_tensors['t_z'] : z_noise,\n",
    "                            })\n",
    "\n",
    "        # print(de)\n",
    "        print(\"g_loss:\", g_loss)\n",
    "\n",
    "        if (batch_no % 30) == 0:\n",
    "            print(\"Saving Images, Model\")\n",
    "            visualize_G(data_dir, real_images, gen, image_files)\n",
    "            save_path = saver.save(sess, \"Data/Models/temp.ckpt\")\n",
    "\n",
    "    if i%5 == 0:\n",
    "        save_path = saver.save(sess, \"Data/Models/ep_{}.ckpt\".format( i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Utils import ops\n",
    "import copy as cp\n",
    "def lrelu(x, leak=0.2):\n",
    "    return tf.maximum(x, leak*x)\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, options):\n",
    "        self.options = options\n",
    "        self.bn =  tf.layers.batch_normalization\n",
    "        self.linear = tf.layers.dense\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        img_size = self.options['image_size']\n",
    "        t_real_image = tf.placeholder('float32', [self.options['batch_size'],img_size, img_size, 3 ], name = 'real_image')\n",
    "        t_wrong_image = tf.placeholder('float32', [self.options['batch_size'],img_size, img_size, 3 ], name = 'wrong_image')\n",
    "        t_real_caption = tf.placeholder('float32', [self.options['batch_size'], self.options['caption_vector_length']], name = 'real_caption_input')\n",
    "        t_z = tf.placeholder('float32', [self.options['batch_size'], self.options['z_dim']])\n",
    "\n",
    "\n",
    "        fake_image,debug = self.generator(t_z, t_real_caption)\n",
    "\n",
    "        # fake_g = tf.image.rgb_to_grayscale(fake_image)\n",
    "        # fake_g = tf.tile(fake_g,[1,1,1,3])\n",
    "\n",
    "        # real_g = tf.image.rgb_to_grayscale(t_real_image)\n",
    "        # real_g = tf.tile(real_g,[1,1,1,3])\n",
    "\n",
    "\n",
    "        pred_real, logit_real    = self.discriminator(t_real_image, t_real_caption,print_dim = True)\n",
    "        pred_wrong, logit_wrong   = self.discriminator(t_wrong_image, t_real_caption)\n",
    "        pred_fake, logit_fake   = self.discriminator(fake_image, t_real_caption)\n",
    "\n",
    "        # pred_real_g, logit_real_g   = self.discriminator(real_g, t_real_caption)\n",
    "        # pred_fake_g, logit_fake_g   = self.discriminator(fake_g, t_real_caption)\n",
    "        \n",
    "\n",
    "        g_loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= logit_fake, labels  = tf.ones_like(pred_fake)))\n",
    "        # g_loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= logit_fake_g, labels  = tf.ones_like(pred_fake_g)))\n",
    "        \n",
    "        self.g_loss = g_loss1\n",
    "        \n",
    "\n",
    "        # soft_bias =tf.random_uniform( pred_real.shape,0, 0.3)\n",
    "        \n",
    "        d_loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= logit_real ,labels  =tf.ones_like(pred_real)))\n",
    "        d_loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= logit_wrong,labels =tf.zeros_like(pred_wrong)))\n",
    "        d_loss3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= logit_fake, labels  =tf.zeros_like(pred_fake)))\n",
    "\n",
    "        # d_loss4 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= logit_real_g, labels  =tf.ones_like(pred_real_g)))\n",
    "        # d_loss5 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= logit_fake_g, labels  =tf.zeros_like(pred_fake_g)))\n",
    "\n",
    "        self.d_loss = d_loss1+(d_loss2+d_loss3)*0.5\n",
    "        # debug = [d_loss4,d_loss5]\n",
    "\n",
    "#########################gradient penalty fail\n",
    "        # LAMBDA = 1.0\n",
    "        # self.epsilon = tf.random_uniform(\n",
    "        #                         shape=[self.options['batch_size'],1,1], \n",
    "        #                         minval=0.,\n",
    "        #                         maxval=1.\n",
    "        #                         )\n",
    "        # interpolates = t_real_image*self.epsilon + (1.0-self.epsilon)*fake_image\n",
    "        # gradients = tf.gradients( self.discriminator(interpolates,t_real_caption)[0], [interpolates])[0]\n",
    "        # self.slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1,2]))\n",
    "\n",
    "        # self.gradient_penalty = tf.reduce_mean((self.slopes-1.)**2)\n",
    "        # self.d_loss += (LAMBDA*self.gradient_penalty)\n",
    "\n",
    "\n",
    "\n",
    "        self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
    "        self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "\n",
    "        input_tensors = {\n",
    "            't_real_image' : t_real_image,\n",
    "            't_wrong_image' : t_wrong_image,\n",
    "            't_real_caption' : t_real_caption,\n",
    "            't_z' : t_z\n",
    "        }\n",
    "\n",
    "        variables = {\n",
    "            'd' : self.d_vars,\n",
    "            'g' : self.g_vars\n",
    "        }\n",
    "\n",
    "        loss = {\n",
    "            'g' : self.g_loss,\n",
    "            'd' : self.d_loss\n",
    "        }\n",
    "\n",
    "        outputs = {\n",
    "            'generator' : fake_image\n",
    "        }\n",
    "\n",
    "        checks = {\n",
    "            'd_loss1': d_loss1,\n",
    "            'd_loss2': d_loss2,\n",
    "            'd_loss3' : d_loss3,\n",
    "            'logit_real ' : logit_real ,\n",
    "            'logit_wrong' : pred_wrong,\n",
    "            'logit_fake' : logit_fake\n",
    "        }\n",
    "        \n",
    "        return input_tensors, variables, loss, outputs, checks,debug\n",
    "\n",
    "    #this will be used in generate_image.py\n",
    "    def build_generator(self):\n",
    "\n",
    "        img_size = self.options['image_size']\n",
    "        t_real_caption = tf.placeholder('float32', [self.options['batch_size'], self.options['caption_vector_length']], name = 'real_caption_input')\n",
    "        t_z = tf.placeholder('float32', [self.options['batch_size'], self.options['z_dim']])\n",
    "        fake_image,_ = self.generator(t_z, t_real_caption)\n",
    "        \n",
    "        input_tensors = {\n",
    "            't_real_caption' : t_real_caption,\n",
    "            't_z' : t_z\n",
    "        }\n",
    "        \n",
    "        outputs = {\n",
    "            'generator' : fake_image\n",
    "        }\n",
    "\n",
    "        return input_tensors, outputs\n",
    "\n",
    "    def generator(self, t_z, t_text_embedding):\n",
    "        with tf.variable_scope(\"generator\", reuse=tf.AUTO_REUSE):\n",
    "            s = self.options['image_size']\n",
    "            s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "            \n",
    "            reduced_text_embedding = lrelu( self.linear(t_text_embedding, self.options['t_dim']) )\n",
    "            z_concat = tf.concat([t_z, reduced_text_embedding],1)\n",
    "            z_ = self.linear(z_concat, self.options['gf_dim']*8*s16*s16)\n",
    "            h0 = tf.reshape(z_, [-1, s16, s16, self.options['gf_dim'] * 8])\n",
    "            h0 = lrelu(self.bn(h0))\n",
    "            h0 = tf.nn.dropout(h0,0.5)\n",
    "\n",
    "            h1 = ops.deconv2d(h0, [self.options['batch_size'], s8, s8, self.options['gf_dim']*4], name='g_h1')\n",
    "            h1 = lrelu(self.bn(h1))\n",
    "            h1 = tf.nn.dropout(h1,0.5)\n",
    "\n",
    "\n",
    "            h2 = ops.deconv2d(h1, [self.options['batch_size'], s4, s4, self.options['gf_dim']*2], name='g_h2')\n",
    "            h2 = lrelu(self.bn(h2))\n",
    "            h2 = tf.nn.dropout(h2,0.5)\n",
    "\n",
    "            h3 = ops.deconv2d(h2, [self.options['batch_size'], s2, s2, self.options['gf_dim']*1], name='g_h3')\n",
    "            h3 = lrelu(self.bn(h3))\n",
    "\n",
    "            h4 = ops.deconv2d(h3, [self.options['batch_size'], s, s, 3], name='g_h4')\n",
    "\n",
    "            print(\"G\",h0.shape,h1.shape,h2.shape,h3.shape,h4.shape)\n",
    "            debug = h4\n",
    "            return (tf.tanh(h4)/2. + 0.5),debug\n",
    "\n",
    "    def discriminator(self, image, t_text_embedding,print_dim =False):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=tf.AUTO_REUSE):\n",
    "            h0 = lrelu(ops.conv2d_legacy(image, self.options['df_dim'])) #32\n",
    "\n",
    "            h1 = lrelu( self.bn(ops.conv2d_legacy(h0, self.options['df_dim']*2, name = 'd_h1_conv'))) #16\n",
    "            h2 = lrelu( self.bn(ops.conv2d_legacy(h1, self.options['df_dim']*4, name = 'd_h2_conv'))) #8\n",
    "            h3 = lrelu( self.bn(ops.conv2d_legacy(h2, self.options['df_dim']*8, name = 'd_h3_conv'))) #4\n",
    "            if print_dim:\n",
    "                print(\"D\",h0.shape,h1.shape,h2.shape,h3.shape)\n",
    "            \n",
    "\n",
    "            # ADD TEXT EMBEDDING TO THE NETWORK\n",
    "            reduced_text_embeddings = lrelu(self.linear(t_text_embedding, self.options['t_dim']))\n",
    "            reduced_text_embeddings = tf.expand_dims(reduced_text_embeddings,1)\n",
    "            reduced_text_embeddings = tf.expand_dims(reduced_text_embeddings,2)\n",
    "            tiled_embeddings = tf.tile(reduced_text_embeddings, [1,4,4,1], name='tiled_embeddings')\n",
    "            \n",
    "            h3_concat = tf.concat(  [h3, tiled_embeddings],3 ,name='h3_concat')\n",
    "            h3_new = lrelu( self.bn(ops.conv2d_legacy(h3_concat, self.options['df_dim']*8, 1,1,1,1, name = 'd_h3_conv_new'))) #4\n",
    "            \n",
    "            h4 = self.linear(tf.reshape(h3_new, [self.options['batch_size'], -1]), 1)\n",
    "            \n",
    "            return tf.nn.sigmoid(h4), h4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
