{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "\n",
    "import string\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import random\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 2428 -> polkadots\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n",
      "5428\n",
      "<RARE>\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path+'/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path+'/word2Id.npy'))\n",
    "id2word_dict =  dict(np.load(dictionary_path+'/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s'%('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s'%('2428', id2word_dict['2428']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s'%(word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))\n",
    "print(word2Id_dict['<RARE>'])\n",
    "print(id2word_dict['5428'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n",
      "5427\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    tokens = []\n",
    "    tokens.extend(nltk.tokenize.word_tokenize(prep_line.lower()))\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    line = [word2Id_dict[tokens[k]] if tokens[k] in word2Id_dict else word2Id_dict['<RARE>'] for k in range(len(tokens))]\n",
    "    \n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "data_path = './dataset'\n",
    "df = pd.read_pickle(data_path+'/text2ImgData.pkl')\n",
    "num_training_sample = len(df)\n",
    "n_images_train = num_training_sample\n",
    "print('There are %d image in training data'%(n_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_DEPTH = 3\n",
    "def training_data_generator(caption, image_path):\n",
    "    # load in the image according to image path\n",
    "    imagefile = tf.read_file(image_path)\n",
    "    image = tf.image.decode_image(imagefile, channels=3)\n",
    "    float_img = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    float_img.set_shape([None, None, 3])\n",
    "    image = float_img\n",
    "    #degrees = tf.random_uniform((1,), 0,10)\n",
    "    #image = tf.contrib.image.rotate(image, degrees * math.pi / 180, interpolation='BILINEAR')\n",
    "    image = tf.image.resize_images(image, size = [80, 80])\n",
    "    image = tf.random_crop(image, size=[64, 64, 3])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    #image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    \n",
    "    image = tf.minimum(image, 1.0)\n",
    "    image = tf.maximum(image, 0.0)\n",
    "    #degrees = tf.random_uniform((1,), 0,45)\n",
    "    #image = tf.contrib.image.rotate(image, degrees * math.pi / 180, interpolation='BILINEAR')\n",
    "    #image = tf.image.flip_left_right(image)\n",
    "    image = (image*2) - 1 \n",
    "    image.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])\n",
    "    \n",
    "    return image, caption\n",
    "\n",
    "def data_iterator(filenames, batch_size, data_generator):\n",
    "    # Load the training data into two NumPy arrays\n",
    "    df = pd.read_pickle(filenames)\n",
    "    captions = df['Captions'].values\n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        word = random.choice(captions[i])\n",
    "        caption.append(word ) \n",
    "    caption = np.asarray(caption)\n",
    "    image_path = df['ImagePath'].values\n",
    "\n",
    "    # Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, image_path))\n",
    "    dataset = dataset.shuffle(7370)\n",
    "    dataset = dataset.map(data_generator)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    output_types = dataset.output_types\n",
    "    output_shapes = dataset.output_shapes\n",
    "    \n",
    "    return iterator, output_types, output_shapes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "BATCH_SIZE = 64\n",
    "iterator_train, types, shapes = data_iterator(data_path+'/text2ImgData.pkl', BATCH_SIZE, training_data_generator)\n",
    "iter_initializer = iterator_train.initializer\n",
    "next_element = iterator_train.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator_train.initializer)\n",
    "    next_element = iterator_train.get_next()\n",
    "    image, text = sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_length(sequence):\n",
    "    mask = tf.logical_not(tf.equal(sequence, word2Id_dict['<PAD>']))\n",
    "    print(mask.shape)\n",
    "    length = tf.reduce_sum(tf.cast(mask,tf.int32), 1)\n",
    "    #length = tf.cast(length, tf.int32)\n",
    "    return length\n",
    "def last_relevant(output, length):\n",
    "    batch_size = tf.shape(output)[0]\n",
    "    max_length = tf.shape(output)[1]\n",
    "    out_size = int(output.get_shape()[2])\n",
    "    index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "    flat = tf.reshape(output, [-1, out_size])\n",
    "    relevant = tf.gather(flat, index)\n",
    "    return relevant\n",
    "class TextEncoder:\n",
    "    \"\"\"\n",
    "    Encode text (a caption) into hidden representation\n",
    "    input: text (a list of id)\n",
    "    output: hidden representation of input text in dimention of TEXT_DIM\n",
    "    \"\"\"\n",
    "    def __init__(self, text, hparas, training_phase=True, reuse=False, return_embed=False):\n",
    "        self.text = text\n",
    "        self.hparas = hparas\n",
    "        self.train = training_phase\n",
    "        self.reuse = reuse\n",
    "        self._build_model()\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('rnnftxt', reuse=self.reuse):\n",
    "            # Word embedding\n",
    "            txt_len = get_length(self.text)\n",
    "            word_embed_matrix = tf.get_variable('rnn/wordembed', \n",
    "                                                shape=(self.hparas['VOCAB_SIZE'], self.hparas['EMBED_DIM']),\n",
    "                                                initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                                dtype=tf.float32)\n",
    "            embedded_word_ids = tf.nn.embedding_lookup(word_embed_matrix, self.text)\n",
    "            # RNN encoder\n",
    "            LSTMCell = tf.nn.rnn_cell.LSTMCell(self.hparas['TEXT_DIM'], \n",
    "                                               initializer=tf.random_normal_initializer(stddev=0.02), \n",
    "                                               reuse=self.reuse)\n",
    "            initial_state = LSTMCell.zero_state(self.hparas['BATCH_SIZE'], dtype=tf.float32)\n",
    "            rnn_net = tf.nn.dynamic_rnn(cell=LSTMCell, \n",
    "                                        inputs=embedded_word_ids, \n",
    "                                        initial_state=initial_state, \n",
    "                                        dtype=np.float32, time_major=False,\n",
    "                                        scope='rnn/dynamic',\n",
    "                                        sequence_length=txt_len)\n",
    "            self.rnn_net = rnn_net\n",
    "            self.outputs = last_relevant(rnn_net[0], txt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Generator:\n",
    "    def __init__(self, noise_z, text, training_phase, hparas, reuse, is_train, p):\n",
    "        self.z = noise_z\n",
    "        self.text = text\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.gf_dim = 128\n",
    "        self.reuse = reuse\n",
    "        self.k_init = tf.random_normal_initializer(stddev=0.02)\n",
    "        self.is_train = is_train\n",
    "        self.keep_prob = p\n",
    "        self._build_model()\n",
    "    def Encode(self, x):\n",
    "\n",
    "        with tf.variable_scope('encode', reuse=self.reuse) as scope:\n",
    "            ep = tf.random_normal(shape=[64, 128])\n",
    "            \n",
    "            fc1 = tf.nn.relu(tf.layers.dense(x, 1024, name='z_fc1', \n",
    "                                         kernel_initializer=self.k_init, reuse=self.reuse))\n",
    "            fc2 = tf.nn.relu(tf.layers.dense(x, 1024, name='z_fc2', \n",
    "                                         kernel_initializer=self.k_init, reuse=self.reuse))\n",
    "            self.z_mean = tf.layers.dense(fc2 , 128, name='z_mean', \n",
    "                                         kernel_initializer=self.k_init, reuse=self.reuse)\n",
    "            self.z_sigma = tf.layers.dense(fc2 , 128, name='z_sigma', \n",
    "                                         kernel_initializer=self.k_init, reuse=self.reuse)\n",
    "            z_x = tf.add(self.z_mean, tf.sqrt(tf.exp(self.z_sigma))*ep)\n",
    "\n",
    "            return z_x    \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('generator', reuse=self.reuse):\n",
    "            gf_dim = 64\n",
    "            g_init = tf.random_normal_initializer(1., 0.2)\n",
    "            #text_flatten = tf.layers.flatten(self.text)\n",
    "            text_input = tf.layers.dense(self.text, self.hparas['TEXT_DIM'], name='generator/text_input', \n",
    "                                         kernel_initializer=self.k_init, reuse=self.reuse)\n",
    "            # \n",
    "            z_text_concat = tf.concat([self.z, text_input], axis=1, name='generator/z_text_concat')\n",
    "            #z_text_concat = self.Encode(z_text_concat)\n",
    "            pre_conv = tf.layers.dense(z_text_concat, gf_dim * 8 * 4 * 4, kernel_initializer=self.k_init, \n",
    "                                       name='generator/pre_dense', reuse=self.reuse)\n",
    "            pre_conv = tf.contrib.gan.features.VBN(pre_conv, gamma_initializer=g_init,name= 'generator/bn0')(pre_conv)\n",
    "            pre_conv = tf.reshape(pre_conv, [-1, 4, 4, gf_dim*8],name='generator/to_conv')\n",
    "            pre_conv = tf.nn.selu(pre_conv, name='generator/act_pre_conv1')\n",
    "            #pre_conv = tf.nn.relu(pre_conv, name='generator/act_pre_conv')\n",
    "            res0 = tf.keras.layers.UpSampling2D(size=(2, 2))(pre_conv)\n",
    "            res0 = tf.layers.conv2d(res0, int(res0.shape[-1]), 1, 1, kernel_initializer=self.k_init, reuse=self.reuse, name='res0')\n",
    "            \n",
    "            upconv_1 = tf.layers.conv2d_transpose(pre_conv, gf_dim * 8, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='generator/upconv1',\n",
    "                                                  reuse=self.reuse)\n",
    "            upconv_1 = tf.contrib.gan.features.VBN(upconv_1, gamma_initializer=g_init, name= 'generator/bn1')(upconv_1)\n",
    "            upconv_1 = tf.nn.selu(upconv_1, name='generator/act_up_conv1') + tf.nn.selu(res0)\n",
    "            res1 = tf.keras.layers.UpSampling2D(size=(2, 2))(upconv_1)\n",
    "            res1 = tf.layers.conv2d(res1, int(res1.shape[-1])//2, 1, 1, kernel_initializer=self.k_init, reuse=self.reuse, name='res1')\n",
    "            #upconv_1 = tf.nn.dropout(upconv_1,self.keep_prob,name='generator/drop1')\n",
    "            upconv_2 = tf.layers.conv2d_transpose(upconv_1, gf_dim * 4, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='generator/upconv2',\n",
    "                                                  reuse=self.reuse)\n",
    "            upconv_2 = tf.contrib.gan.features.VBN(upconv_2, gamma_initializer=g_init, name= 'generator/bn2')(upconv_2)\n",
    "            upconv_2 = tf.nn.selu(upconv_2, name='generator/act_up_conv2') + tf.nn.selu(res1)\n",
    "            res2 = tf.keras.layers.UpSampling2D(size=(2, 2))(upconv_2)\n",
    "            res2 = tf.layers.conv2d(res2, int(res2.shape[-1])//2, 1, 1, kernel_initializer=self.k_init, reuse=self.reuse, name='res2')\n",
    "            \n",
    "            upconv_3 = tf.layers.conv2d_transpose(upconv_2, gf_dim*2, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='generator/upconv3',\n",
    "                                                  reuse=self.reuse)\n",
    "            upconv_3 = tf.contrib.gan.features.VBN(upconv_3, gamma_initializer=g_init, name= 'generator/bn3')(upconv_3)\n",
    "            upconv_3 = tf.nn.selu(upconv_3, name='generator/act_up_conv3') + tf.nn.selu(res2)\n",
    "            res3 = tf.keras.layers.UpSampling2D(size=(2, 2))(upconv_3)\n",
    "            res3 = tf.layers.conv2d(res3, 16, 1, 1, kernel_initializer=self.k_init, reuse=self.reuse, name='res3')\n",
    "            #upconv_3 = tf.nn.dropout(upconv_3, self.keep_prob,name='generator/drop2')\n",
    "            \n",
    "            upconv_4 = tf.layers.conv2d_transpose(upconv_3, 16, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='generator/upconv4',\n",
    "                                                  reuse=self.reuse)\n",
    "            upconv_4 = tf.contrib.gan.features.VBN(upconv_4, gamma_initializer=g_init, name= 'generator/bn4')(upconv_4)\n",
    "            upconv_4 = tf.nn.selu(upconv_4, name='generator/act_up_conv4') \n",
    "            upconv_4 = tf.layers.conv2d_transpose(upconv_4, 3, 1, 1, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='generator/upconv4_2',\n",
    "                                                  reuse=self.reuse)\n",
    "            #upconv_4 = tf.layers.batch_normalization(upconv_4, training=self.is_train, gamma_initializer=g_init, name= 'generator/bn4')\n",
    "            upconv_fn = tf.identity(upconv_4, name='generator/act_up_logit')\n",
    "            \n",
    "            g_net = tf.nn.tanh(upconv_fn, name='generator/act_up_convfn')\n",
    "            \n",
    "            self.generator_net = g_net\n",
    "            self.outputs = g_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resnet structure\n",
    "class Discriminator:\n",
    "    def __init__(self, image, text, training_phase, hparas, reuse, is_train):\n",
    "        self.image = image\n",
    "        self.text = text\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.df_dim = 64 # 196 for MSCOCO\n",
    "        self.reuse = reuse\n",
    "        self.k_init = tf.random_normal_initializer(stddev=0.02)\n",
    "        self.is_train = is_train\n",
    "        self.act_fn = tf.nn.leaky_relu\n",
    "        \n",
    "        self._build_model()\n",
    "        \n",
    "    \n",
    "    def _build_model(self):        \n",
    "        with tf.variable_scope('discriminator', reuse=self.reuse):\n",
    "            g_init = tf.random_normal_initializer(1., 0.1)\n",
    "            edge = tf.reduce_mean(self.image, -1,keepdims=True)\n",
    "            kernel_h = np.array([ [1,2,1], [0,0,0], [-1,-2,-1] ])/4\n",
    "            kernel_v = np.array([ [1,0,-1], [2,0,-2], [1,0,-1] ])/4\n",
    "            conv_w_h = tf.constant(kernel_h, dtype=tf.float32, shape=(3, 3, 1, 1),name='Const_h')\n",
    "            conv_w_v = tf.constant(kernel_v, dtype=tf.float32, shape=(3, 3, 1, 1),name='Const_v')    \n",
    "            edge1 = tf.nn.conv2d(input=edge, filter=conv_w_h, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            edge2 = tf.nn.conv2d(input=edge, filter=conv_w_v, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.image = tf.concat([self.image, (edge1+edge2)/2], 3)\n",
    "            conv_1 = tf.layers.conv2d(self.image, self.df_dim, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='discriminator/conv1',\n",
    "                                                  reuse=self.reuse)\n",
    "            conv_1 = tf.contrib.layers.layer_norm(conv_1)\n",
    "            conv_1 = self.act_fn(conv_1, name='discriminator/act_conv1')\n",
    "            res0 = tf.layers.conv2d(conv_1, self.df_dim*4, 1, 1, kernel_initializer=self.k_init, reuse=self.reuse, name='res0')\n",
    "            res0 = tf.layers.average_pooling2d(res0,5,2,padding='same')\n",
    "\n",
    "            conv_2 = tf.layers.conv2d(conv_1, self.df_dim*4, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='discriminator/conv2',\n",
    "                                                  reuse=self.reuse)\n",
    "            conv_2 = tf.contrib.layers.layer_norm(conv_2)\n",
    "            conv_2 = self.act_fn(conv_2, name='discriminator/act_conv2')\n",
    "            res1 = tf.layers.conv2d(conv_2, self.df_dim*6, 1, 1, kernel_initializer=self.k_init, reuse=self.reuse, name='res1')\n",
    "            res1 = tf.layers.average_pooling2d(res1,5,2,padding='same')\n",
    "            conv_3 = tf.layers.conv2d(conv_2, self.df_dim*6, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='discriminator/conv3',\n",
    "                                                  reuse=self.reuse)\n",
    "            conv_3 = tf.contrib.layers.layer_norm(conv_3)\n",
    "            conv_3 = self.act_fn(conv_3, name='discriminator/act_conv3')\n",
    "            \n",
    "            # multi-task branch\n",
    "            dim_3 = tf.layers.conv2d(conv_3, self.df_dim*3, 5, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='discriminator/dim3_1',\n",
    "                                                  reuse=self.reuse)\n",
    "            dim_3 = tf.contrib.layers.layer_norm(dim_3)\n",
    "            dim_3 = self.act_fn(dim_3)\n",
    "            dim_3 = tf.layers.conv2d(dim_3, self.df_dim, 1, 1, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='discriminator/dim3_2',\n",
    "                                                  reuse=self.reuse)\n",
    "            dim_3 = tf.contrib.layers.layer_norm(dim_3)\n",
    "            dim_3 = self.act_fn(dim_3)\n",
    "            flat_3 = tf.layers.flatten(dim_3,'f_conv')\n",
    "            self._to_rnn = tf.layers.dense(flat_3, 128, kernel_initializer=self.k_init, \n",
    "                                       name='discriminator/_to_rnn', reuse=self.reuse)\n",
    "            \n",
    "            # Text part\n",
    "            text_flat = tf.layers.flatten(self.text,'f_text')\n",
    "            text_in = tf.layers.dense(text_flat, self.df_dim*6, kernel_initializer=self.k_init, \n",
    "                                       name='discriminator/pre_dense', reuse=self.reuse)   \n",
    "            text_in = self.act_fn(text_in)\n",
    "            text_in = tf.expand_dims(tf.expand_dims(text_in,1),1)\n",
    "            text_in = tf.tile(text_in, [1, conv_3.shape[1],conv_3.shape[2], 1])\n",
    "            feature_concat = tf.concat([text_in, conv_3], 3)\n",
    "            feature_concat = tf.contrib.layers.layer_norm(feature_concat)\n",
    "            \n",
    "            \n",
    "            conv_4 = tf.layers.conv2d(feature_concat, self.df_dim*6, 1, 1, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='discriminator/conv4',\n",
    "                                                  reuse=self.reuse)\n",
    "            conv_4 = tf.contrib.layers.layer_norm(conv_4)\n",
    "            conv_4 = self.act_fn(conv_4, name='discriminator/act_conv4')\n",
    "            \n",
    "            conv_5 = tf.layers.conv2d(conv_4, self.df_dim*8, 2, 2, padding='same', \n",
    "                                                 kernel_initializer=self.k_init, name='discriminator/conv5',\n",
    "                                                  reuse=self.reuse)\n",
    "            conv_5 = tf.contrib.layers.layer_norm(conv_5)\n",
    "            conv_5 = self.act_fn(conv_5, name='discriminator/act_conv5')\n",
    "            \n",
    "            conv_5_flat = tf.layers.flatten(conv_5,'f_text')\n",
    "            self.logits = tf.layers.dense(conv_5_flat, 1, kernel_initializer=self.k_init, \n",
    "                                       name='discriminator/final', reuse=self.reuse)              \n",
    "            self.discriminator_net = self.logits\n",
    "            self.outputs = self.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hparas():\n",
    "    hparas = {\n",
    "        'MAX_SEQ_LENGTH' : 20,\n",
    "        'EMBED_DIM' : 128, # word embedding dimension\n",
    "        'VOCAB_SIZE' : len(vocab)+1,\n",
    "        'TEXT_DIM' : 128, # text embedding dimension\n",
    "        'RNN_HIDDEN_SIZE' : 128,\n",
    "        'Z_DIM' : 128, # random noise z dimension\n",
    "        'IMAGE_SIZE' : [64, 64, 3], # render image size\n",
    "        'BATCH_SIZE' : 64,\n",
    "        'LR' : 2e-4,\n",
    "        'BETA' : 0., # AdamOptimizer parameter\n",
    "        'N_EPOCH' : 800*5,\n",
    "        'N_SAMPLE' : num_training_sample\n",
    "    }\n",
    "    return hparas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, hparas, training_phase, dataset_path, ckpt_path, inference_path, recover=None):\n",
    "        self.hparas = hparas\n",
    "        self.train = training_phase\n",
    "        self.dataset_path = dataset_path # dataPath+'/text2ImgData.pkl'\n",
    "        self.ckpt_path = ckpt_path\n",
    "        self.sample_path = './samples'\n",
    "        self.inference_path = './inference'\n",
    "        self.train_compare = False\n",
    "        \n",
    "        self._get_session() # get session\n",
    "        self._get_train_data_iter() # initialize and get data iterator\n",
    "        self._input_layer() # define input placeholder\n",
    "        self._get_inference() # build generator and discriminator\n",
    "        self._get_loss() # define gan loss\n",
    "        self._get_var_with_name() # get variables for each part of model\n",
    "        self._optimize() # define optimizer\n",
    "        self._init_vars()\n",
    "        self._get_saver()\n",
    "        self.fixed_sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(self.hparas['BATCH_SIZE'], self.hparas['Z_DIM'])).astype(np.float32)\n",
    "        if recover is not None:\n",
    "            self._load_checkpoint(recover)\n",
    "            \n",
    "            \n",
    "        \n",
    "    def _get_train_data_iter(self):\n",
    "        if self.train: # training data iteratot\n",
    "            iterator_train, types, shapes = data_iterator(self.dataset_path+'/text2ImgData.pkl',\n",
    "                                                          self.hparas['BATCH_SIZE'], training_data_generator)\n",
    "            iter_initializer = iterator_train.initializer\n",
    "            self.next_element = iterator_train.get_next()\n",
    "            self.sess.run(iterator_train.initializer)\n",
    "            self.iterator_train = iterator_train\n",
    "        else: # testing data iterator\n",
    "            iterator_test, types, shapes = data_iterator_test(self.dataset_path+'/testData.pkl', self.hparas['BATCH_SIZE'])\n",
    "            iter_initializer = iterator_test.initializer\n",
    "            self.next_element = iterator_test.get_next()\n",
    "            self.sess.run(iterator_test.initializer)\n",
    "            self.iterator_test = iterator_test\n",
    "            \n",
    "    def _input_layer(self):\n",
    "        if self.train:\n",
    "            self.real_image = tf.placeholder('float32',\n",
    "                                              [self.hparas['BATCH_SIZE'], self.hparas['IMAGE_SIZE'][0],\n",
    "                                               self.hparas['IMAGE_SIZE'][1], self.hparas['IMAGE_SIZE'][2]],\n",
    "                                              name='real_image')\n",
    "            self.noise_level = tf.placeholder('float32', shape=(),name='n_level')\n",
    "            self.real_image_n = self.real_image #+ tf.random_normal(shape=tf.shape(self.real_image), mean=0.0, stddev=self.noise_level, dtype=tf.float32)\n",
    "            self.caption = tf.placeholder(dtype=tf.int64, shape=[self.hparas['BATCH_SIZE'], None], name='caption')\n",
    "            self.z_noise = tf.placeholder(tf.float32, [self.hparas['BATCH_SIZE'], self.hparas['Z_DIM']], name='z_noise')\n",
    "            self.training_flags = tf.placeholder(dtype=tf.bool, name='is_train')\n",
    "            self.keep_prob = tf.placeholder(dtype=tf.float32, name='k_prob')\n",
    "             \n",
    "        else:\n",
    "            self.caption = tf.placeholder(dtype=tf.int64, shape=[self.hparas['BATCH_SIZE'], None], name='caption')\n",
    "            self.z_noise = tf.placeholder(tf.float32, [self.hparas['BATCH_SIZE'], self.hparas['Z_DIM']], name='z_noise')\n",
    "            self.training_flags = tf.placeholder(dtype=tf.bool, name='is_train')\n",
    "            self.keep_prob = tf.placeholder(dtype=tf.float32, name='k_prob')\n",
    "    def _get_inference(self):\n",
    "        if self.train:\n",
    "            # GAN training\n",
    "            # encoding text\n",
    "            text_encoder = TextEncoder(self.caption, hparas = self.hparas, training_phase=True, reuse=False)\n",
    "            self.text_encoder = text_encoder\n",
    "            print(text_encoder.outputs.shape)\n",
    "            # generating image\n",
    "            generator = Generator(self.z_noise, text_encoder.outputs, training_phase=True,\n",
    "                                  hparas=self.hparas, reuse=False, is_train = self.training_flags,p=self.keep_prob)\n",
    "            self.generator = generator\n",
    "            print(generator.outputs.shape)\n",
    "            \n",
    "            # discriminize\n",
    "            # fake image\n",
    "            fake_discriminator = Discriminator(generator.outputs, text_encoder.outputs,\n",
    "                                               training_phase=True, hparas=self.hparas, reuse=False, is_train = self.training_flags)\n",
    "            self.fake_discriminator = fake_discriminator\n",
    "            # real image\n",
    "            real_discriminator = Discriminator(self.real_image_n, text_encoder.outputs, training_phase=True,\n",
    "                                              hparas=self.hparas, reuse=True, is_train = self.training_flags)\n",
    "            # Wrong caption\n",
    "            self.roll_caps = tf.roll(text_encoder.outputs, 10, 0)\n",
    "            #if self.train_compare:\n",
    "            #    print('Training with mismatch samples')\n",
    "            self.wrong_discriminator = Discriminator(self.real_image_n, self.roll_caps, training_phase=True,\n",
    "                                             hparas=self.hparas, reuse=True, is_train = self.training_flags)\n",
    "            \n",
    "            \n",
    "            self.real_discriminator = real_discriminator\n",
    "            #alph = tf.random.uniform([self.hparas['BATCH_SIZE'], 1, 1, 1], 0., 1.)\n",
    "            difference = self.generator.outputs - self.real_image_n\n",
    "            interpolates = 0.5*self.real_image_n + 0.5*difference\n",
    "            interpolates = tf.reshape(interpolates, self.real_image.shape)\n",
    "            text_embd = text_encoder.outputs\n",
    "            inter_discriminator = Discriminator(interpolates, text_embd, training_phase=True,\n",
    "                                             hparas=self.hparas, reuse=True, is_train = self.training_flags)\n",
    "            l_gp = tf.gradients(self.real_discriminator.outputs, [self.real_image_n])\n",
    "            gradients = l_gp[0] #+ 1e-8\n",
    "            #gradients_embd = l_gp[1]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=list(range(1, self.real_image_n.shape.ndims))))\n",
    "            #slopes_embd = tf.sqrt(tf.reduce_sum(tf.square(gradients_embd), axis=list(range(1, text_embd.shape.ndims))))\n",
    "            self.gradient_penalty = tf.reduce_mean(tf.maximum(0.0, slopes)**2) #+ tf.reduce_mean(tf.maximum(0.0, slopes_embd)**2)\n",
    "            \n",
    "        else: # inference mode\n",
    "            \n",
    "            self.text_embed = TextEncoder(self.caption, hparas=self.hparas, training_phase=False, reuse=False)\n",
    "            self.generate_image_net = Generator(self.z_noise, self.text_embed.outputs, training_phase=False,\n",
    "                                                hparas=self.hparas, reuse=False, is_train = self.training_flags, p=self.keep_prob)\n",
    "    def KL_loss(self, mu, log_var):\n",
    "        return -0.5 * tf.reduce_sum(1 + log_var - tf.pow(mu, 2) - tf.exp(log_var))\n",
    "        \n",
    "    def _get_loss(self):\n",
    "        if self.train:\n",
    "#             d_loss1 =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.real_discriminator.logits,\n",
    "#                                                                             labels=0.9*tf.ones_like(self.real_discriminator.logits),\n",
    "#                                                                             name='d_loss1'))\n",
    "            d_loss1 = tf.reduce_mean(self.real_discriminator.logits)\n",
    "#             d_loss2 =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.fake_discriminator.logits,\n",
    "#                                                                             labels=tf.zeros_like(self.fake_discriminator.logits),\n",
    "#                                                                             name='d_loss2'))\n",
    "            d_loss2 = tf.reduce_mean(self.fake_discriminator.logits)\n",
    "            \n",
    "            d_loss3 = tf.reduce_mean(self.wrong_discriminator.logits)\n",
    "#             d_loss3 =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.wrong_discriminator.logits,\n",
    "#                                                                             labels=tf.zeros_like(self.fake_discriminator.logits),\n",
    "#                                                                             name='d_loss2'))            \n",
    "            #if self.train_compare:\n",
    "            #d_loss3 = tf.reduce_mean(self.wrong_discriminator.logits)\n",
    "            #self.d_loss = (d_loss2 + d_loss3)/2 - d_loss1 + 10 * self.gradient_penalty\n",
    "#             self.g_loss =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.fake_discriminator.logits,\n",
    "#                                                                                  labels=tf.ones_like(self.fake_discriminator.logits),\n",
    "#                                                                                 name='g_loss'))\n",
    "            #d_loss3 = tf.reduce_mean(self.wrong_discriminator.logits)\n",
    "            #self.rnn_loss = d_loss3 - d_loss1\n",
    "            word_sim_T = tf.reduce_sum(self.real_discriminator._to_rnn * self.text_encoder.outputs,1)/(tf.sqrt(tf.reduce_sum(self.real_discriminator._to_rnn* self.real_discriminator._to_rnn, 1)+1e-8) * tf.sqrt(tf.reduce_sum(self.text_encoder.outputs* self.text_encoder.outputs, 1)+1e-8))\n",
    "            word_sim_F = tf.reduce_sum(self.wrong_discriminator._to_rnn * self.roll_caps,1)/(tf.sqrt(tf.reduce_sum(self.wrong_discriminator._to_rnn* self.wrong_discriminator._to_rnn, 1)+1e-8) *  tf.sqrt(tf.reduce_sum(self.roll_caps* self.roll_caps, 1)+1e-8))\n",
    "            self.rnn_loss = tf.reduce_mean(tf.maximum(0., 0.5-word_sim_T+word_sim_F))\n",
    "            #self.kl_loss = self.KL_loss(self.generator.z_mean, self.generator.z_sigma)\n",
    "            self.d_loss = (d_loss2)  -  d_loss1 + self.rnn_loss +10 * self.gradient_penalty# + self.kl_loss\n",
    "            self.g_loss = -d_loss2 #+ self.kl_loss/(128*64)\n",
    "                        \n",
    "\n",
    "    def _optimize(self):\n",
    "        if self.train:\n",
    "            with tf.variable_scope('learning_rate'):\n",
    "                self.lr_var = tf.Variable(self.hparas['LR'], trainable=False)\n",
    "\n",
    "            discriminator_optimizer = tf.train.AdamOptimizer(self.lr_var, beta1=self.hparas['BETA'])\n",
    "            #discriminator_optimizer = tf.contrib.opt.AdamWOptimizer(0.005, self.lr_var, beta1=self.hparas['BETA'])\n",
    "            #discriminator_optimizer = tf.train.RMSPropOptimizer(self.lr_var)\n",
    "            generator_optimizer = tf.train.AdamOptimizer(self.lr_var, beta1=self.hparas['BETA'])\n",
    "            #rnn_optimizer = tf.train.AdamOptimizer(self.lr_var, beta1=self.hparas['BETA'])\n",
    "            #generator_optimizer = tf.contrib.opt.AdamWOptimizer(0.0005, self.lr_var, beta1=self.hparas['BETA'])\n",
    "            #generator_optimizer = tf.train.RMSPropOptimizer(self.lr_var)\n",
    "            self.d_optim = discriminator_optimizer.minimize(self.d_loss, var_list=self.discrim_vars)\n",
    "            self.d_optim_nornn =  discriminator_optimizer.minimize(self.d_loss, var_list=self.discrim_vars)\n",
    "            self.g_optim = generator_optimizer.minimize(self.g_loss, var_list=self.generator_vars)\n",
    "            #self.rnn_optim = rnn_optimizer.minimize(self.rnn_loss, var_list=self.text_encoder_vars)\n",
    "            # mix_loss\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.rnn_loss, self.text_encoder_vars), 10)\n",
    "            rnn_optimizer = tf.train.AdamOptimizer(self.lr_var, beta1=self.hparas['BETA'])\n",
    "            self.rnn_optim = rnn_optimizer.apply_gradients(zip(grads, self.text_encoder_vars))\n",
    "            \n",
    "            self.weight_clip_ops = []\n",
    "\n",
    "#             for var in self.discrim_vars:            \n",
    "#                 self.weight_clip_ops.append(var.assign(tf.clip_by_value(var, -0.01, 0.01)))\n",
    "    def training(self):\n",
    "        n_level = 0.01\n",
    "        g_loss = d_loss = 0\n",
    "        for _epoch in range(self.hparas['N_EPOCH']):\n",
    "            start_time = time.time()\n",
    "            n_critic = 1\n",
    "            n_batch_epoch = int(self.hparas['N_SAMPLE']/self.hparas['BATCH_SIZE'])\n",
    "            current_num = n_critic\n",
    "            if _epoch < 60:\n",
    "                n_level = n_level\n",
    "            else:\n",
    "                n_level = n_level - 0.001   \n",
    "            n_level = np.maximum(0.0, n_level)\n",
    "            for _step in range(n_batch_epoch):\n",
    "                if current_num == 0:\n",
    "                    current_num = n_critic\n",
    "                step_time = time.time()\n",
    "                image_batch, caption_batch = self.sess.run(self.next_element)\n",
    "                b_z = np.random.normal(loc=0.0, scale=1.0, \n",
    "                                       size=(self.hparas['BATCH_SIZE'], self.hparas['Z_DIM'])).astype(np.float32)\n",
    "\n",
    "                # update discriminator\n",
    "                #if _epoch < 60:\n",
    "                self.discriminator_error, _ = self.sess.run([self.d_loss, self.d_optim],\n",
    "                                                           feed_dict={\n",
    "                                                                self.real_image:image_batch,\n",
    "                                                                self.caption:caption_batch,\n",
    "                                                                self.z_noise:b_z,\n",
    "                                                                self.training_flags:True,\n",
    "                                                                self.noise_level: n_level, \n",
    "                                                                self.keep_prob:1})\n",
    "#                 else:\n",
    "#                     self.discriminator_error, _ = self.sess.run([self.d_loss, self.d_optim_nornn],\n",
    "#                                                                feed_dict={\n",
    "#                                                                     self.real_image:image_batch,\n",
    "#                                                                     self.caption:caption_batch,\n",
    "#                                                                     self.z_noise:b_z,\n",
    "#                                                                     self.training_flags:True,\n",
    "#                                                                     self.noise_level: n_level, \n",
    "#                                                                     self.keep_prob:1})\n",
    "                d_loss = self.discriminator_error\n",
    "#                     self.rnn_error, _ = self.sess.run([self.rnn_loss, self.rnn_optim],\n",
    "#                                                                feed_dict={\n",
    "#                                                                     self.real_image:image_batch,\n",
    "#                                                                     self.caption:caption_batch,\n",
    "#                                                                     self.z_noise:b_z,\n",
    "#                                                                     self.training_flags:True,\n",
    "#                                                                     self.keep_prob:1})\n",
    "                    #rnn_loss = self.rnn_error\n",
    "                if current_num == 1:\n",
    "                    self.generator_error, _ = self.sess.run([self.g_loss, self.g_optim],\n",
    "                                       feed_dict={self.caption: caption_batch, \n",
    "                                                  self.z_noise : b_z,\n",
    "                                                  self.training_flags:True,\n",
    "                                                  self.noise_level: n_level,\n",
    "                                                  self.keep_prob:0.8})\n",
    "                    g_loss = self.generator_error\n",
    "                self.rnn_optim\n",
    "                self.rnn_error, _ = self.sess.run([self.rnn_loss, self.rnn_optim],\n",
    "                                       feed_dict={self.real_image:image_batch,\n",
    "                                                  self.caption:caption_batch,\n",
    "                                                  self.z_noise:b_z,\n",
    "                                                  self.training_flags:True,\n",
    "                                                  self.noise_level: n_level, \n",
    "                                                  self.keep_prob:1})\n",
    "                #n_level -= 1./self.hparas['N_EPOCH']/int(self.hparas['N_SAMPLE']/self.hparas['BATCH_SIZE'])                 \n",
    "                \n",
    "                \n",
    "                if _step%50==0:\n",
    "                    print(\"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4fs, d_loss: %.3f, g_loss: %.3f, rnn_loss: %.3f\" \\\n",
    "                            % (_epoch, self.hparas['N_EPOCH'], _step, n_batch_epoch, time.time() - step_time,\n",
    "                               d_loss, g_loss, self.rnn_error))\n",
    "            if _epoch != 0 and (_epoch+1)%1==0:\n",
    "                self._save_checkpoint(_epoch)\n",
    "                self._sample_visiualize(_epoch)\n",
    "            \n",
    "    def inference(self):\n",
    "        for _iters in range(100):\n",
    "            caption, idx = self.sess.run(self.next_element)\n",
    "            z_seed = np.random.normal(loc=0.0, scale=1.0, size=(self.hparas['BATCH_SIZE'], self.hparas['Z_DIM'])).astype(np.float32)\n",
    "\n",
    "            img_gen, rnn_out = self.sess.run([self.generate_image_net.outputs, self.text_embed.outputs],\n",
    "                                             feed_dict={self.caption : caption, self.z_noise : z_seed, self.training_flags:False,self.keep_prob:1})\n",
    "            img_gen = (img_gen + 1)/2\n",
    "            for i in range(self.hparas['BATCH_SIZE']):\n",
    "                scipy.misc.imsave(self.inference_path+'/inference_{:04d}.png'.format(idx[i]), img_gen[i])\n",
    "                \n",
    "    def _init_vars(self):\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _get_session(self):\n",
    "        self.sess = tf.Session()\n",
    "    \n",
    "    def _get_saver(self):\n",
    "        if self.train:\n",
    "            self.rnn_saver = tf.train.Saver(var_list=self.text_encoder_vars)\n",
    "            self.g_saver = tf.train.Saver(var_list=self.generator_vars)\n",
    "            self.d_saver = tf.train.Saver(var_list=self.discrim_vars)\n",
    "        else:\n",
    "            self.rnn_saver = tf.train.Saver(var_list=self.text_encoder_vars)\n",
    "            self.g_saver = tf.train.Saver(var_list=self.generator_vars)\n",
    "            \n",
    "    def _sample_visiualize(self, epoch):\n",
    "        ni = int(np.ceil(np.sqrt(self.hparas['BATCH_SIZE'])))\n",
    "        sample_size = self.hparas['BATCH_SIZE']\n",
    "        max_len = self.hparas['MAX_SEQ_LENGTH']\n",
    "        \n",
    "        sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(self.hparas['BATCH_SIZE'], self.hparas['Z_DIM'])).astype(np.float32)\n",
    "        sample_sentence = [\"the flower shown has yellow anther red pistil and bright red petals.\"]*int(sample_size/ni) + [\"this flower has petals that are yellow, white and purple and has dark lines\"]*int(sample_size/ni) + [\"the petals on this flower are white with a yellow center\"] * int(sample_size/ni) + [\"this flower has a lot of small round pink petals.\"] * int(sample_size/ni) + [\"this flower is orange in color, and has petals that are ruffled and rounded.\"] * int(sample_size/ni) + [\"the flower has yellow petals and the center of it is brown.\"] * int(sample_size/ni) + [\"this flower has petals that are blue and white.\"] * int(sample_size/ni) + [\"these white flowers have petals that start off white in color and end in a white towards the tips.\"] * int(sample_size/ni)\n",
    "\n",
    "        for i, sent in enumerate(sample_sentence):\n",
    "            sample_sentence[i] = sent2IdList(sent, max_len)\n",
    "            \n",
    "        img_gen, rnn_out = self.sess.run([self.generator.outputs, self.text_encoder.outputs],\n",
    "                                         feed_dict={self.caption : sample_sentence, self.z_noise : self.fixed_sample_seed, self.training_flags:False,self.keep_prob:1})\n",
    "        save_images((img_gen + 1)/2, [ni, ni], self.sample_path+'/train_{:02d}.png'.format(epoch))\n",
    "        \n",
    "    def _get_var_with_name(self):\n",
    "        t_vars = tf.trainable_variables()\n",
    "\n",
    "        self.text_encoder_vars = [var for var in t_vars if 'rnn' in var.name]\n",
    "        self.generator_vars = [var for var in t_vars if 'generator' in var.name]\n",
    "        self.discrim_vars = [var for var in t_vars if 'discrim' in var.name]\n",
    "    \n",
    "    def _load_checkpoint(self, recover):\n",
    "        if self.train:\n",
    "            self.rnn_saver.restore(self.sess, self.ckpt_path+'rnn_model_'+str(recover)+'.ckpt')\n",
    "            self.g_saver.restore(self.sess, self.ckpt_path+'g_model_'+str(recover)+'.ckpt')\n",
    "            self.d_saver.restore(self.sess, self.ckpt_path+'d_model_'+str(recover)+'.ckpt')\n",
    "        else:\n",
    "            self.rnn_saver.restore(self.sess, self.ckpt_path+'rnn_model_'+str(recover)+'.ckpt')\n",
    "            self.g_saver.restore(self.sess, self.ckpt_path+'g_model_'+str(recover)+'.ckpt')\n",
    "        print('-----success restored checkpoint--------')\n",
    "    \n",
    "    def _save_checkpoint(self, epoch):\n",
    "        self.rnn_saver.save(self.sess, self.ckpt_path+'rnn_model_'+str(epoch)+'.ckpt')\n",
    "        self.g_saver.save(self.sess, self.ckpt_path+'g_model_'+str(epoch)+'.ckpt')\n",
    "        self.d_saver.save(self.sess, self.ckpt_path+'d_model_'+str(epoch)+'.ckpt')\n",
    "        print('-----success saved checkpoint--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, ?)\n",
      "(64, 128)\n",
      "(64, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "checkpoint_path = './checkpoint/'\n",
    "inference_path = './inference'\n",
    "gan = GAN(get_hparas(), training_phase=True, dataset_path=data_path, ckpt_path=checkpoint_path, inference_path=inference_path)\n",
    "gan.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_iterator_test(filenames, batch_size):\n",
    "    data = pd.read_pickle(filenames)\n",
    "    captions = data['Captions'].values\n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(captions[i])\n",
    "    caption = np.asarray(caption)\n",
    "    index = data['ID'].values\n",
    "    index = np.asarray(index)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, index))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    output_types = dataset.output_types\n",
    "    output_shapes = dataset.output_shapes\n",
    "    \n",
    "    return iterator, output_types, output_shapes\n",
    "tf.reset_default_graph()\n",
    "iterator_train, types, shapes = data_iterator_test(data_path+'/testData.pkl', 64)\n",
    "iter_initializer = iterator_train.initializer\n",
    "next_element = iterator_train.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator_train.initializer)\n",
    "    next_element = iterator_train.get_next()\n",
    "    caption, idex = sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, ?)\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/rnn_model_3.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/g_model_3.ckpt\n",
      "-----success restored checkpoint--------\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "gan = GAN(get_hparas(), training_phase=False, dataset_path=data_path, ckpt_path=checkpoint_path, inference_path=inference_path, recover=3)\n",
    "img = gan.inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
