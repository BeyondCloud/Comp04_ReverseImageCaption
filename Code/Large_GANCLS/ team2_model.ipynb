{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import copy as cp\n",
    "import string\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import random\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "import model\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "img_size = 64\n",
    "z_dim = 512\n",
    "t_dim = 256\n",
    "df_dim = 64\n",
    "gf_dim = 128\n",
    "\n",
    "\n",
    "lr = 0.0002\n",
    "lr_decay = 0.5      \n",
    "decay_every = 100  \n",
    "save_dir = './checkpoint'\n",
    "restore_model = '/VBN700/modelVBN.ckpt'\n",
    "n_caps = 5\n",
    "warnings.filterwarnings('ignore')\n",
    "ni = int(np.ceil(np.sqrt(batch_size)))\n",
    "sample_size = batch_size\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\n",
    "test_sentence = pd.read_csv('test.csv',dtype={'ID':'str'})\n",
    "sample_sentence = []\n",
    "for i in range(64):\n",
    "    sample_sentence.append(test_sentence['Captions'].values[i])\n",
    "\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2IdList(sent)\n",
    "\n",
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path+'/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path+'/word2Id.npy'))\n",
    "id2word_dict =  dict(np.load(dictionary_path+'/id2Word.npy'))\n",
    "\n",
    "\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "\n",
    "train_img = np.load('train_images.npy', encoding='latin1')\n",
    "train_cap = np.load('train_captions.npy', encoding='latin1')\n",
    "\n",
    "cap_lst = []\n",
    "for caps in train_cap:\n",
    "    cap_lst.append(caps[:n_caps])\n",
    "train_cap = np.concatenate(cap_lst, axis=0) \n",
    "\n",
    "\n",
    "\n",
    "model_options = {\n",
    "    'z_dim' : z_dim,\n",
    "    'batch_size' : batch_size,\n",
    "    'img_size' :img_size,\n",
    "    't_dim' :t_dim,\n",
    "    'df_dim' :df_dim,\n",
    "    'gf_dim' :gf_dim,\n",
    "    'vocab_size':  len(vocab)\n",
    "}\n",
    "\n",
    "gan = model.GAN(model_options)\n",
    "\n",
    "\n",
    "input_tensors,loss,net= gan.build_model()\n",
    "\n",
    "d_loss = loss['d']\n",
    "g_loss = loss['g']\n",
    "rnn_loss = loss['r']\n",
    "net_g = net['net_g']\n",
    "\n",
    "net_rnn = net['net_rnn']\n",
    "\n",
    "\n",
    "\n",
    "rnn_vars = [var for var in tf.trainable_variables() if 'rnn' in var.name]\n",
    "g_vars = [var for var in tf.trainable_variables() if 'generator' in var.name]\n",
    "d_vars = [var for var in tf.trainable_variables() if 'discrim' in var.name]\n",
    "cnn_vars = [var for var in tf.trainable_variables() if 'cnn' in var.name]\n",
    "\n",
    "update_ops_D = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'discrim' in var.name]\n",
    "update_ops_G = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'generator' in var.name]\n",
    "update_ops_CNN = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'cnn' in var.name]\n",
    "\n",
    "\n",
    "with tf.variable_scope('learning_rate'):\n",
    "    lr_v = tf.Variable(lr, trainable=False)\n",
    "\n",
    "with tf.control_dependencies(update_ops_D):\n",
    "    d_optim = tf.train.AdamOptimizer(lr_v, beta1=0.5).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "with tf.control_dependencies(update_ops_G):\n",
    "    g_optim = tf.train.AdamOptimizer(lr_v, beta1=0.5).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "with tf.control_dependencies(update_ops_CNN):\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(rnn_loss, rnn_vars + cnn_vars), 10)\n",
    "    optimizer = tf.train.AdamOptimizer(lr_v, beta1=0.5)\n",
    "    rnn_optim = optimizer.apply_gradients(zip(grads, rnn_vars + cnn_vars))\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=5)\n",
    "\n",
    "try:\n",
    "    ckpt_path  = save_dir+restore_model\n",
    "    saver.restore(sess, ckpt_path)\n",
    "    print(\"Restore model\",ckpt_path)\n",
    "except:\n",
    "    print('no model found.')\n",
    "\n",
    "n_epoch = 700\n",
    "n_batch_epoch = int(len(train_img) / batch_size)\n",
    "train_img_lr = cp.copy(train_img)\n",
    "train_img_ud = cp.copy(train_img)\n",
    "train_img_udlr = cp.copy(train_img)\n",
    "\n",
    "for i,img in enumerate(train_img):\n",
    "    train_img_lr[i] = train_img[i][:, ::-1]\n",
    "for i,img in enumerate(train_img):\n",
    "    train_img_ud[i] = np.flipud(train_img[i])\n",
    "for i,img in enumerate(train_img_ud):\n",
    "    train_img_udlr[i] = np.flipud(train_img_lr[i])\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "    if epoch !=0 and (epoch % decay_every == 0):\n",
    "        new_lr_decay = lr_decay ** (epoch // decay_every)\n",
    "        sess.run(tf.assign(lr_v, lr * new_lr_decay))\n",
    "        log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n",
    "        print(log)\n",
    "        \n",
    "    elif epoch == 0:\n",
    "        log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n",
    "        print(log)\n",
    "\n",
    "    for step in range(n_batch_epoch):\n",
    "        step_time = time.time()\n",
    "\n",
    "        ## get matched text & image\n",
    "        # idxs = get_random_int(min=0, max=len(train_cap)-1, number=batch_size)\n",
    "        idxs = np.random.randint(low = 0,high = len(train_cap), size=batch_size)\n",
    "        real_caption = train_cap[idxs]\n",
    "\n",
    "        r = np.random.randint(4, size=(1))\n",
    "        if r == 0:\n",
    "            real_images = train_img[np.floor(np.asarray(idxs).astype('float')/n_caps).astype('int')]\n",
    "        elif r==1:\n",
    "            real_images = train_img_lr[np.floor(np.asarray(idxs).astype('float')/n_caps).astype('int')]\n",
    "        elif r ==2:\n",
    "            real_images = train_img_ud[np.floor(np.asarray(idxs).astype('float')/n_caps).astype('int')]\n",
    "        elif r == 3:\n",
    "            real_images = train_img_udlr[np.floor(np.asarray(idxs).astype('float')/n_caps).astype('int')]\n",
    "        ## get wrong caption & wrong image\n",
    "        # idxs = get_random_int(min=0, max=len(train_cap)-1, number=batch_size)\n",
    "        idxs = np.random.randint(low = 0,high = len(train_cap), size=batch_size)\n",
    "\n",
    "        wrong_caption = train_cap[idxs]\n",
    "        # idxs2 = get_random_int(min=0, max=len(train_img)-1, number=batch_size)\n",
    "        idxs2 = np.random.randint(low = 0,high = len(train_img), size=batch_size)\n",
    "        \n",
    "        wrong_images = train_img[idxs2]\n",
    "\n",
    "        ## get noise\n",
    "        b_z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim)).astype(np.float32)\n",
    "\n",
    "        real_images = threading_data(real_images, prepro_img, mode='train')   # [0, 255] --> [-1, 1] + augmentation\n",
    "        wrong_images = threading_data(wrong_images, prepro_img, mode='train')\n",
    "\n",
    "        # ## update RNN\n",
    "        # if epoch < 80:\n",
    "        R_loss, _ = sess.run([rnn_loss, rnn_optim], feed_dict={\n",
    "                                        input_tensors['t_real_image'] : real_images,\n",
    "                                        input_tensors['t_wrong_image'] : wrong_images,\n",
    "                                        input_tensors['t_real_caption'] : real_caption,\n",
    "                                        input_tensors['t_wrong_caption'] : wrong_caption})\n",
    "        # else:\n",
    "        #     R_loss = 0\n",
    "\n",
    "        ## updates D\n",
    "        D_loss, _ = sess.run([d_loss, d_optim], feed_dict={\n",
    "                        input_tensors['t_real_image']  : real_images,\n",
    "                        input_tensors['t_wrong_caption']  : wrong_caption,\n",
    "                        input_tensors['t_real_caption']  : real_caption,\n",
    "                        input_tensors['t_z']  : b_z})\n",
    "        ## updates G\n",
    "        G_loss, _ = sess.run([g_loss, g_optim], feed_dict={\n",
    "                        input_tensors['t_real_caption'] : real_caption,\n",
    "                        input_tensors['t_z'] : b_z})\n",
    "\n",
    "        print(\"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4fs, d_loss: %.8f, g_loss: %.8f, rnn_loss: %.8f\" \\\n",
    "                    % (epoch, n_epoch, step, n_batch_epoch, time.time() - step_time, D_loss, G_loss, R_loss))\n",
    "\n",
    "        # print('d/g/r',D_loss,G_loss,R_loss)\n",
    "    \n",
    "        if step == 0:\n",
    "            print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\n",
    "            img_gen, rnn_out = sess.run([net_g.out, net_rnn.out], feed_dict={\n",
    "                                        input_tensors['t_real_caption'] : sample_sentence,\n",
    "                                        input_tensors['t_z']  : sample_seed})\n",
    "            print(\"min:\",np.min(img_gen),\"max:\",np.max(img_gen))\n",
    "            img_gen = img_gen*0.5+0.5\n",
    "            scipy.misc.imsave('train_samples/train_{:03d}.png'.format(epoch), merge(img_gen, [ni, ni]))\n",
    "    if  (epoch % 10) == 0:\n",
    "\n",
    "        saver.save(sess,save_dir+'/modelVBN.ckpt')\n",
    "        print(\"model save to\",save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "from layer_utils import *\n",
    "lrelu = lambda x: tf.nn.leaky_relu(x, 0.2)\n",
    "relu = lambda x: tf.nn.relu(x)\n",
    "class GAN:\n",
    "    def __init__(self, options):\n",
    "        self.options = options\n",
    "    def build_model(self):\n",
    "        batch_size = self.options['batch_size']\n",
    "        img_size = self.options['img_size']\n",
    "        z_dim = self.options['z_dim']\n",
    "\n",
    "        t_real_image = tf.placeholder('float32', [batch_size, img_size, img_size, 3], name = 'real_image')\n",
    "        t_wrong_image = tf.placeholder('float32', [batch_size ,img_size, img_size, 3], name = 'wrong_image')\n",
    "        t_real_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='real_caption_input')\n",
    "        t_wrong_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='wrong_caption_input')\n",
    "        t_z = tf.placeholder('float32', [batch_size, z_dim])\n",
    "\n",
    "\n",
    "        x   = cnn_encoder(t_real_image,option = self.options,is_training=True, reuse=False).out\n",
    "        v   = TextEncoder(t_real_caption,option = self.options ,is_training=True, reuse=False).out\n",
    "        x_w = cnn_encoder(t_wrong_image,option = self.options, is_training=True, reuse=True).out\n",
    "        v_w = TextEncoder(t_wrong_caption,option = self.options ,is_training=True, reuse=True).out\n",
    "\n",
    "        alpha = 0.2 # margin alpha\n",
    "        rnn_loss = tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x, v_w))) + \\\n",
    "                    tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x_w, v)))\n",
    "\n",
    "        ### Training Phase - GAN\n",
    "        net_rnn = TextEncoder(t_real_caption, option = self.options,is_training=False, reuse=True)\n",
    "        net_fake_image = Generator(t_z, net_rnn.out,option = self.options, is_training=True, reuse=False)\n",
    "                \n",
    "        disc_fake = Discriminator(net_fake_image.out, net_rnn.out, is_training=True, reuse=False)\n",
    "\n",
    "        disc_real = Discriminator(t_real_image, net_rnn.out, is_training=True, reuse=True)\n",
    "\n",
    "\n",
    "        disc_wrong = Discriminator(t_real_image, \n",
    "                                    TextEncoder(t_wrong_caption, option = self.options,is_training=False, reuse=True).out,\n",
    "                                    is_training=True, reuse=True)\n",
    "\n",
    "        d_loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_real.logits,labels=tf.ones_like(disc_real.logits)*0.9,name='d1'))\n",
    "        d_loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_wrong.logits, labels=tf.zeros_like(disc_wrong.logits)+0.1, name='d2'))\n",
    "        d_loss3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake.logits,labels=tf.zeros_like(disc_fake.logits)+0.1,name='d3'))\n",
    "        d_loss = d_loss1 + (d_loss2 + d_loss3) * 0.5\n",
    "        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake.logits, labels=tf.ones_like(disc_fake.logits)*0.9, name='g'))\n",
    "        \n",
    "\n",
    "        #Use for visualization\n",
    "        net_g = Generator(t_z,TextEncoder(t_real_caption,option = self.options, is_training=False, reuse=True).out,option = self.options,is_training=False, reuse=True)\n",
    "\n",
    "        input_tensors = {\n",
    "            't_real_image' : t_real_image,\n",
    "            't_wrong_image' : t_wrong_image,\n",
    "            't_real_caption' : t_real_caption,\n",
    "            't_wrong_caption' : t_wrong_caption,\n",
    "            't_z':t_z\n",
    "        }\n",
    "        loss = {\n",
    "            'g' : g_loss,\n",
    "            'd' : d_loss,\n",
    "            'r' : rnn_loss\n",
    "        }\n",
    "        net = {\n",
    "            'net_g':net_g,\n",
    "            'net_rnn':net_rnn   \n",
    "        }\n",
    "        return input_tensors,loss,net\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, input_z, input_txt,option, is_training, reuse):\n",
    "        self.input_z = input_z\n",
    "        self.input_txt = input_txt\n",
    "        self.is_training = is_training\n",
    "        self.reuse = reuse\n",
    "        self.t_dim = option['t_dim']\n",
    "        self.gf_dim = option['gf_dim']\n",
    "        self.image_size = option['img_size']\n",
    "        self.c_dim = 3\n",
    "        self.VBN = tf.contrib.gan.features.VBN\n",
    "\n",
    "        \n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        s = self.image_size\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "\n",
    "        gf_dim = self.gf_dim\n",
    "        t_dim = self.t_dim\n",
    "        c_dim = self.c_dim\n",
    "\n",
    "        with tf.variable_scope(\"generator\", reuse=self.reuse):\n",
    "            net_txt = DenseLayer(inputs=self.input_txt, n_units=t_dim, act=tf.nn.leaky_relu, name='rnn_fc')\n",
    "\n",
    "            net_in = ConcatLayer([self.input_z, net_txt], concat_dim=1, name='concat_z_txt')\n",
    "\n",
    "            net_h0 = DenseLayer(inputs=net_in, n_units=gf_dim*8*s16*s16, name='g_h0/fc', b_init=False)\n",
    "            # net_h0 = BatchNormLayer(net_h0, act=None, is_training=self.is_training, name='g_h0/batch_norm')\n",
    "            net_h0 = self.VBN(net_h0,name='g_h0/batch_norm')(net_h0)\n",
    "\n",
    "            net_h0 = tf.reshape(net_h0, [-1, s16, s16, gf_dim*8], name='g_h0/reshape')\n",
    "\n",
    "            net_h0 = tf.layers.dropout(net_h0,0.5)\n",
    "\n",
    "            net = Conv2d(net_h0,gf_dim*2, (1,1),  (1,1),padding='VALID', name='g_h1_res/conv2d')\n",
    "\n",
    "            # net = BatchNormLayer(net, act=relu, is_training=self.is_training, name='g_h1_res/batch_norm')\n",
    "            net = self.VBN(net, name='g_h1_res/batch_norm')(net)\n",
    "            net = relu(net)\n",
    "            net = Conv2d(net,gf_dim*2,  (3,3), (1,1), name='g_h1_res/conv2d2', padding='SAME')\n",
    "            # net = BatchNormLayer(net, act=relu, is_training=self.is_training, name='g_h1_res/batch_norm2')\n",
    "            net = self.VBN(net,  name='g_h1_res/batch_norm2')(net)\n",
    "            net = relu(net)\n",
    "            net = Conv2d(net, gf_dim*8,(3,3),  (1,1), name='g_h1_res/conv2d3', padding='SAME')\n",
    "            \n",
    "            # net = BatchNormLayer(net, act=None, is_training=self.is_training, name='g_h1_res/batch_norm3')\n",
    "            net = self.VBN(net, name='g_h1_res/batch_norm3')(net)\n",
    "\n",
    "            net_h1 = tf.add_n([net_h0, net], name='g_h1_res/add')\n",
    "            net_h1_output = relu(net_h1)\n",
    "            \n",
    "            net_h2 = UpSample(net_h1_output, size=[s8, s8], method=1, align_corners=False, name='g_h2/upsample2d')\n",
    "            net_h2 = Conv2d(net_h2, gf_dim*4,(3,3), (1,1), name='g_h2/conv2d', padding='SAME')\n",
    "            # net_h2 = BatchNormLayer(net_h2, act=None, is_training=self.is_training, name='g_h2/batch_norm')\n",
    "            net_h2 = self.VBN(net_h2,name='g_h2/batch_norm')(net_h2)\n",
    "            net_h2 = relu(net_h2)\n",
    "\n",
    "            net = Conv2d(net_h2,gf_dim, (1,1),  (1,1), name='g_h3_res/conv2d')\n",
    "            # net = BatchNormLayer(net, act=relu, is_training=self.is_training, name='g_h3_res/batch_norm')\n",
    "            net = self.VBN(net, name='g_h3_res/batch_norm')(net)\n",
    "            net = relu(net)\n",
    "            net = Conv2d(net,gf_dim, (3,3), (1,1), name='g_h3_res/conv2d2', padding='SAME')\n",
    "            # net = BatchNormLayer(net, act=relu, is_training=self.is_training, name='g_h3_res/batch_norm2')\n",
    "            net = self.VBN(net, name='g_h3_res/batch_norm2')(net)\n",
    "            net = relu(net)\n",
    "            net = Conv2d(net,gf_dim*4,(3,3), (1,1), name='g_h3_res/conv2d3', padding='SAME')\n",
    "            # net = BatchNormLayer(net, act=None, is_training=self.is_training, name='g_h3_res/batch_norm3')\n",
    "            net = self.VBN(net, name='g_h3_res/batch_norm3')(net)\n",
    "\n",
    "            net_h3 = tf.add_n([net_h2, net], name='g_h3/add')\n",
    "            net_h3_outputs = relu(net_h3)\n",
    "\n",
    "            net_h4 = UpSample(net_h3_outputs, size=[s4, s4], method=1, align_corners=False, name='g_h4/upsample2d')\n",
    "            net_h4 = Conv2d(net_h4,gf_dim*2, (3,3), (1,1) , name='g_h4/conv2d', padding='SAME')\n",
    "            # net_h4 = BatchNormLayer(net_h4, act=relu, is_training=self.is_training, name='g_h4/batch_norm')\n",
    "            net_h4 = self.VBN(net_h4, name='g_h4/batch_norm')(net_h4)\n",
    "            net_h4 = relu(net_h4)\n",
    "\n",
    "            net_h5 = UpSample(net_h4, size=[s2, s2], method=1, align_corners=False, name='g_h5/upsample2d')\n",
    "            net_h5 = Conv2d(net_h5, gf_dim, (3,3), (1,1), name='g_h5/conv2d', padding='SAME')\n",
    "            # net_h5 = BatchNormLayer(net_h5, act=relu, is_training=self.is_training, name='g_h5/batch_norm')\n",
    "            net_h5 = self.VBN(net_h5, name='g_h5/batch_norm')(net_h5)\n",
    "            net_h5 = relu(net_h5)\n",
    "\n",
    "            net_ho = UpSample(net_h5, size=[s, s], method=1, align_corners=False, name='g_ho/upsample2d')\n",
    "            net_ho = Conv2d(net_ho,c_dim,(3,3),  (1,1), name='g_ho/conv2d', padding='SAME', b_init=True) ## b_init = True\n",
    "\n",
    "            self.logits = net_ho\n",
    "            # self.out = tf.nn.tanh(self.logits)*0.5+0.5\n",
    "            self.out = tf.nn.tanh(self.logits)\n",
    "            \n",
    "\n",
    "\n",
    "class Discriminator:\n",
    "    def __init__(self, input_image, input_txt, is_training, reuse):\n",
    "        self.input_image = input_image\n",
    "        self.input_txt = input_txt\n",
    "        self.is_training = is_training\n",
    "        self.reuse = reuse\n",
    "        self.df_dim = 64\n",
    "        self.t_dim = 128\n",
    "        self.image_size = 64\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        s = self.image_size\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "\n",
    "        df_dim = self.df_dim\n",
    "        t_dim = self.t_dim\n",
    "\n",
    "        with tf.variable_scope(\"discriminator\", reuse=self.reuse):\n",
    "            net_h0 = Conv2d(self.input_image, df_dim,(4,4),(2, 2), name='d_h0/conv2d', act=tf.nn.leaky_relu, padding='SAME', b_init=True)\n",
    "\n",
    "            net_h1 = Conv2d(net_h0,df_dim*2, (4,4), (2, 2), name='d_h1/conv2d', padding='SAME')\n",
    "            net_h1 = BatchNormLayer(net_h1, act=tf.nn.leaky_relu, is_training=self.is_training, name='d_h1/batchnorm')\n",
    "\n",
    "            net_h2 = Conv2d(net_h1,df_dim*4, (4,4), (2, 2), name='d_h2/conv2d', padding='SAME')\n",
    "            net_h2 = BatchNormLayer(net_h2, act=tf.nn.leaky_relu, is_training=self.is_training, name='d_h2/batchnorm')\n",
    "\n",
    "            net_h3 = Conv2d(net_h2,df_dim*8, (4,4), (2, 2), name='d_h3/conv2d', padding='SAME')\n",
    "            net_h3 = BatchNormLayer(net_h3, act=None, is_training=self.is_training, name='d_h3/batchnorm')\n",
    "\n",
    "            net = Conv2d(net_h3,df_dim*2,(1, 1),  (1, 1), name='d_h4_res/conv2d')\n",
    "            net = BatchNormLayer(net, act=tf.nn.leaky_relu, is_training=self.is_training, name='d_h4_res/batchnorm')\n",
    "            net = Conv2d(net, df_dim*2,(3, 3),  (1, 1), name='d_h4_res/conv2d2', padding='SAME')\n",
    "            net = BatchNormLayer(net, act=tf.nn.leaky_relu, is_training=self.is_training, name='d_h4_res/batchnorm2')\n",
    "            net = Conv2d(net,df_dim*8, (3, 3),  (1, 1), name='d_h4_res/conv2d3', padding='SAME')\n",
    "            net = BatchNormLayer(net, act=None, is_training=self.is_training, name='d_h4_res/batchnorm3')\n",
    "\n",
    "            net_h4 = tf.add_n([net_h3, net], name='d_h4/add')\n",
    "            net_h4_outputs = tf.nn.leaky_relu(net_h4)\n",
    "\n",
    "            net_txt = DenseLayer(self.input_txt, n_units=t_dim, act=tf.nn.leaky_relu, name='d_reduce_txt/dense')\n",
    "            net_txt = tf.expand_dims(net_txt, axis=1, name='d_txt/expanddim1')\n",
    "            net_txt = tf.expand_dims(net_txt, axis=1, name='d_txt/expanddim2')\n",
    "            net_txt = tf.tile(net_txt, [1, 4, 4, 1], name='d_txt/tile')\n",
    "            \n",
    "            net_h4_concat = ConcatLayer([net_h4_outputs, net_txt], concat_dim=3, name='d_h3_concat')\n",
    "\n",
    "            net_h4 = Conv2d(net_h4_concat, df_dim*8,(1, 1),  (1, 1), name='d_h3/conv2d_2')\n",
    "            net_h4 = BatchNormLayer(net_h4, act=tf.nn.leaky_relu, is_training=self.is_training, name='d_h3/batch_norm_2')\n",
    "\n",
    "            net_ho = Conv2d(net_h4, 1, (s16, s16),  (s16, s16), name='d_ho/conv2d', b_init=True) # b_init = True\n",
    "            self.logits = net_ho\n",
    "            self.out = tf.nn.sigmoid(net_ho)\n",
    "\n",
    "\n",
    "\n",
    "#Modified from course slide\n",
    "class TextEncoder:\n",
    "    def __init__(self, input_seqs,option, is_training, reuse):\n",
    "        self.input_seqs = input_seqs\n",
    "\n",
    "        self.t_dim = option['t_dim']\n",
    "        self.rnn_hidden_size = 128\n",
    "        self.vocab_size = option['vocab_size']\n",
    "        self.word_embedding_size = 256\n",
    "        self.batch_size = option['batch_size']\n",
    "        self.is_training = is_training        \n",
    "        self.reuse = reuse\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    \n",
    "        with tf.variable_scope(\"rnnftxt\", reuse=self.reuse):\n",
    "            word_embed_matrix = tf.get_variable('rnn/wordembed', \n",
    "                shape=(self.vocab_size, self.word_embedding_size),\n",
    "                initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                dtype=tf.float32)\n",
    "            embedded_word_ids = tf.nn.embedding_lookup(word_embed_matrix, self.input_seqs)\n",
    "\n",
    "            # RNN encoder\n",
    "            LSTMCell = tf.contrib.rnn.BasicLSTMCell(self.t_dim, reuse=self.reuse)\n",
    "            initial_state = LSTMCell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "            network  = tf.nn.dynamic_rnn(cell=LSTMCell,\n",
    "                                    inputs=embedded_word_ids,\n",
    "                                    initial_state=initial_state,\n",
    "                                    dtype=np.float32,\n",
    "                                    time_major=False,\n",
    "                                    scope='rnn/dynamic')\n",
    "        self.out = network[0][:, -1, :]\n",
    "\n",
    "class cnn_encoder:\n",
    "    def __init__(self, inputs,option,is_training=True, reuse=False):\n",
    "        self.inputs = inputs\n",
    "        self.df_dim = option['df_dim']\n",
    "        self.t_dim = option['t_dim']\n",
    "        self.is_training = is_training\n",
    "        self.reuse = reuse\n",
    "        self.build_model()\n",
    "    def build_model(self):\n",
    "        df_dim = self.df_dim\n",
    "\n",
    "        with tf.variable_scope('cnnftxt', reuse=self.reuse):\n",
    "            net_h0 = Conv2d(self.inputs,df_dim,(4,4),(2,2), name='cnnf/h0/conv2d', act=tf.nn.leaky_relu, padding='SAME', b_init=True)\n",
    "            \n",
    "            net_h1 = Conv2d(net_h0,df_dim*2,(4,4),(2,2), name='cnnf/h1/conv2d', padding='SAME')\n",
    "            net_h1 = BatchNormLayer(net_h1, act=tf.nn.leaky_relu, is_training=self.is_training, name='cnnf/h1/batch_norm')\n",
    "\n",
    "            net_h2 = Conv2d(net_h1,df_dim*4,(4,4),(2,2), name='cnnf/h2/conv2d', padding='SAME')\n",
    "            net_h2 = BatchNormLayer(net_h2, act=tf.nn.leaky_relu, is_training=self.is_training, name='cnnf/h2/batch_norm')\n",
    "\n",
    "            net_h3 = Conv2d(net_h2, df_dim*8,(4,4),(2,2), name='cnnf/h3/conv2d', padding='SAME')\n",
    "            net_h3 = BatchNormLayer(net_h3, act=tf.nn.leaky_relu, is_training=self.is_training, name='cnnf/h3/batch_norm')\n",
    "\n",
    "            net_h4 = flatten(net_h3, name='cnnf/h4/flatten')\n",
    "            net_h4 = DenseLayer(net_h4, n_units=self.t_dim, name='cnnf/h4/embed', b_init=False)\n",
    "        \n",
    "        self.out = net_h4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
